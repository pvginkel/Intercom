#include "support.h"

#include "I2SRecordingDevice.h"

#define SAMPLE_RATE 16000

LOG_TAG(I2SRecordingDevice);

I2SRecordingDevice::I2SRecordingDevice() : _feed_buffer(CONFIG_DEVICE_AUDIO_CHUNK_LEN * 2) {}

void I2SRecordingDevice::begin() {
    begin_i2s();
    begin_afe();

    xTaskCreate([](void *param) { ((I2SRecordingDevice *)param)->forward_task(); }, "I2SRecordingDevice::forward_task",
                CONFIG_ESP_MAIN_TASK_STACK_SIZE, this, 5, nullptr);
}

void I2SRecordingDevice::begin_i2s() {
    i2s_chan_config_t chan_config = I2S_CHANNEL_DEFAULT_CONFIG(I2S_NUM_1, I2S_ROLE_MASTER);
    ESP_ERROR_CHECK(i2s_new_channel(&chan_config, NULL, &_chan));

    i2s_std_config_t rx_std_cfg = {
        .clk_cfg = I2S_STD_CLK_DEFAULT_CONFIG(SAMPLE_RATE),
        .slot_cfg =
            {
                .data_bit_width = I2S_DATA_BIT_WIDTH_32BIT,
                .slot_bit_width = I2S_SLOT_BIT_WIDTH_32BIT,
                .slot_mode = I2S_SLOT_MODE_MONO,
                .slot_mask = I2S_STD_SLOT_LEFT,
                .ws_width = 32,
                .ws_pol = false,
                .bit_shift = false,
                .left_align = true,
                .big_endian = false,
                .bit_order_lsb = false,
            },
        .gpio_cfg =
            {
                .mclk = I2S_GPIO_UNUSED,
                .bclk = (gpio_num_t)CONFIG_DEVICE_MICROPHONE_SCK_PIN,
                .ws = (gpio_num_t)CONFIG_DEVICE_MICROPHONE_WS_PIN,
                .dout = I2S_GPIO_UNUSED,
                .din = (gpio_num_t)CONFIG_DEVICE_MICROPHONE_DATA_PIN,
                .invert_flags =
                    {
                        .mclk_inv = false,
                        .bclk_inv = false,
                        .ws_inv = false,
                    },
            },
    };
    ESP_ERROR_CHECK(i2s_channel_init_std_mode(_chan, &rx_std_cfg));
}

void I2SRecordingDevice::begin_afe() {
    _models = esp_srmodel_init("model");

    auto afe_config = afe_config_init("MR", _models, AFE_TYPE_VC, AFE_MODE_HIGH_PERF);

    /********** AEC(Acoustic Echo Cancellation) **********/
    // Whether to init aec
    assert(afe_config->aec_init == true);
    // The mode of aec, AEC_MODE_SR_LOW_COST or AEC_MODE_SR_HIGH_PERF
    // afe_config->aec_mode;
    // The filter length of aec
    // afe_config->aec_filter_length;

    /********** SE(Speech Enhancement, microphone array processing) **********/
    // Whether to init se
    assert(afe_config->se_init == false);

    /********** NS(Noise Suppression) **********/
    // Whether to init ns
    assert(afe_config->ns_init == true);
    // Model name of ns
    // afe_config->ns_model_name;
    // Model mode of ns
    // afe_config->afe_ns_mode;

    /********** VAD(Voice Activity Detection) **********/
    // Whether to init vad
    afe_config->vad_init = false;
    // The value can be: VAD_MODE_0, VAD_MODE_1, VAD_MODE_2, VAD_MODE_3, VAD_MODE_4
    // afe_config->vad_mode;
    // The model name of vad, If it is null, WebRTC VAD will be used.
    // afe_config->vad_model_name;
    // The minimum duration of speech in ms. It should be bigger than 32 ms, default: 128 ms
    // afe_config->vad_min_speech_ms;
    // The minimum duration of noise or silence in ms. It should be bigger than 64 ms, default:
    // 1000 ms
    // afe_config->vad_min_noise_ms;
    // The delay of the first speech frame in ms, default: 128 ms
    // If you find vad cache can not cover all speech, please increase this value.
    // afe_config->vad_delay_ms;
    // If true, the playback will be muted for vad detection. default: false
    // afe_config->vad_mute_playback;
    // If true, the vad will be used to choose the channel id. default: false
    // afe_config->vad_enable_channel_trigger;

    /********** WakeNet(Wake Word Engine) **********/
    assert(afe_config->wakenet_init == false);
    // The model name of wakenet 1
    // afe_config->wakenet_model_name;
    // The model name of wakenet 2 if has wakenet 2
    // afe_config->wakenet_model_name_2;
    // The mode of wakenet
    // afe_config->wakenet_mode;

    /********** AGC(Automatic Gain Control) **********/
    // Whether to init agc
    afe_config->agc_init = true;
    // The AGC mode for ASR. and the gain generated by AGC acts on the audio after far linear gain.
    assert(afe_config->agc_mode == AFE_AGC_MODE_WEBRTC);
    // Compression gain in dB (default 9)
    assert(afe_config->agc_compression_gain_db == 9);
    // Target level in -dBfs of envelope (default -3)
    assert(afe_config->agc_target_level_dbfs == 3);

    /********** General AFE(Audio Front End) parameter **********/
    // Config the channel num of original data which is fed to the afe feed function.
    // afe_config->pcm_config;
    // The mode of afe， AFE_MODE_LOW_COST or AFE_MODE_HIGH_PERF
    // afe_config->afe_mode;
    // The mode of afe， AFE_MODE_LOW_COST or AFE_MODE_HIGH_PERF
    // afe_config->afe_type;
    // The preferred core of afe se task, which is created in afe_create function.
    afe_config->afe_perferred_core = 1;
    // afe_config->afe_perferred_core;
    // The preferred priority of afe se task, which is created in afe_create function.
    // afe_config->afe_perferred_priority;
    // The ring buffer size: the number of frame data in ring buffer.
    // afe_config->afe_ringbuf_size;
    // The memory alloc mode for afe. From Internal RAM or PSRAM
    // afe_config->memory_alloc_mode;
    // The linear gain for afe output the value should be in [0.1, 10.0]. This value acts directly on the output
    // amplitude: out_linear_gain * amplitude.
    // afe_config->afe_linear_gain;
    // afe_config->debug_init;
    // If true, the channel after first wake-up is fixed to raw data of microphone
    // otherwise, select channel number by wakenet
    // afe_config->fixed_first_channel;

    _afe_handle = esp_afe_handle_from_config(afe_config);
    _afe_data = _afe_handle->create_from_config(afe_config);

    afe_config_free(afe_config);
}

bool I2SRecordingDevice::start() {
    bool result = false;

    {
        auto guard = _lock.take();

        if (_recording) {
            ESP_LOGE(TAG, "Starting recorder while device is still recording");
        } else {
            ESP_LOGI(TAG, "Starting recorder");

            result = true;
            _recording = true;

            // AFE requires a significantly larger than normal stack.
            const int AFE_TASK_SIZE = 8291;

            xTaskCreate([](void *param) { ((I2SRecordingDevice *)param)->read_task(); },
                        "I2SRecordingDevice::read_task", AFE_TASK_SIZE, this, 5, nullptr);
        }
    }

    if (result) {
        _recording_changed.call(true);
    }

    return true;
}

bool I2SRecordingDevice::stop() {
    bool result = false;

    {
        auto guard = _lock.take();

        if (!_recording) {
            ESP_LOGE(TAG, "Stopping recorder while the device isn't recording");
        } else {
            ESP_LOGI(TAG, "Stopping recorder");

            result = true;
            _recording = false;
        }
    }

    if (result) {
        _recording_changed.call(false);
    }

    return result;
}

void I2SRecordingDevice::feed_reference_samples(uint8_t *buffer, size_t len) {
    auto guard = _lock.take();

    _feed_buffer.write(buffer, len);
}

void I2SRecordingDevice::read_task() {
    const auto feed_chunksize = _afe_handle->get_feed_chunksize(_afe_data);
    const auto feed_nch = _afe_handle->get_feed_channel_num(_afe_data);
    assert(feed_nch == 2);
    const auto feed_buffer_len = feed_chunksize * feed_nch * sizeof(int16_t);
    const auto feed_buffer = (int16_t *)malloc(feed_buffer_len);
    ESP_ERROR_ASSERT(feed_buffer);
    const auto reference_buffer = (int16_t *)malloc(feed_buffer_len);
    ESP_ERROR_ASSERT(reference_buffer);
    size_t feed_buffer_offset = 0;
    int missed_reference_samples = 0;
    time_t last_report = 0;

    // We keep the sample buffer equal to the feed buffer to keep latency down.
    const auto buffer_len = feed_chunksize * 1 /* mono */ * sizeof(int32_t);
    const auto buffer = malloc(buffer_len);
    ESP_ERROR_ASSERT(buffer);

    ESP_ERROR_CHECK(i2s_channel_enable(_chan));

    while (_recording) {
        if (missed_reference_samples) {
            const auto millis = esp_get_millis();
            if (last_report + 1000 < millis) {
                ESP_LOGW(TAG, "Missed reference samples %d", missed_reference_samples);

                last_report = millis;
                missed_reference_samples = 0;
            }
        }

        size_t read;
        ESP_ERROR_CHECK(i2s_channel_read(_chan, buffer, buffer_len, &read, portMAX_DELAY));

        size_t reference_read;

        {
            auto guard = _lock.take();

            reference_read = _feed_buffer.read(reference_buffer, buffer_len);
        }

        auto source = (int32_t *)buffer;
        auto samples = read / sizeof(int32_t);
        const auto reference_samples = reference_read / sizeof(int16_t);

        if (reference_samples < samples) {
            missed_reference_samples += samples - reference_samples;
        }

        for (int i = 0; i < samples; i++) {
            // The INMP441 writes bits 1 through 24. To get the 16 MSB bits, we need
            // to shift away 15 bits. We shift a few bits less to gain the audio
            // signal early on in the process.
            const auto sample = (int16_t)(source[i] >> (15 - CONFIG_DEVICE_MICROPHONE_GAIN_BITS));

            const auto reference_sample = i < reference_samples ? reference_buffer[i] : 0;

            feed_buffer[feed_buffer_offset++] = sample;            // Left mic.
            feed_buffer[feed_buffer_offset++] = reference_sample;  // Playback/reference channel.

            if (feed_buffer_offset * sizeof(int16_t) >= feed_buffer_len) {
                _afe_handle->feed(_afe_data, feed_buffer);
                feed_buffer_offset = 0;
            }
        }
    }

    ESP_LOGI(TAG, "Exiting read task");

    ESP_ERROR_CHECK(i2s_channel_disable(_chan));

    free(buffer);
    free(feed_buffer);
    vTaskDelete(nullptr);
}

void I2SRecordingDevice::forward_task() {
    while (true) {
        auto res = _afe_handle->fetch_with_delay(_afe_data, portMAX_DELAY);
        ESP_ERROR_ASSERT(res);
        ESP_ERROR_CHECK(res->ret_value);

        _data_available.call({(uint8_t *)res->data, (size_t)res->data_size});
    }
}
